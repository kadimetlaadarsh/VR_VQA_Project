{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11827247,"sourceType":"datasetVersion","datasetId":7429866},{"sourceId":11827409,"sourceType":"datasetVersion","datasetId":7429981},{"sourceId":11840651,"sourceType":"datasetVersion","datasetId":7439380}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets peft scikit-learn pandas pillow\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T15:24:58.619666Z","iopub.execute_input":"2025-05-16T15:24:58.619898Z","iopub.status.idle":"2025-05-16T15:26:16.797813Z","shell.execute_reply.started":"2025-05-16T15:24:58.619882Z","shell.execute_reply":"2025-05-16T15:26:16.796927Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from datasets import Dataset\nimport torch\nfrom transformers import (\n    BlipForQuestionAnswering,\n    BlipProcessor,\n    TrainingArguments,\n    Trainer\n)\nfrom peft import LoraConfig, get_peft_model\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport os\nfrom PIL import Image\n\n# 1. Dataset Preparation -----------------------------------------------\n# Load and flatten your dataset\ndf = pd.read_csv(\"/kaggle/input/merged-one/merged_vqa_dataset_output.csv\")\nBASE_IMAGE_DIR = \"/kaggle/input/abo-dataset/images/small\"\n\n# Flatten into (image_path, question, answer) format\nsamples = []\nfor _, row in df.iterrows():\n    for q_col, a_col in zip(['q1', 'q2', 'q3'], ['a1', 'a2', 'a3']):\n        samples.append({\n            \"image_path\": os.path.join(BASE_IMAGE_DIR, row['path']),\n            \"question\": row[q_col],\n            \"answer\": row[a_col]\n        })\n\n# Split into train/test\ntrain_df, test_df = train_test_split(pd.DataFrame(samples), test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T15:26:16.798876Z","iopub.execute_input":"2025-05-16T15:26:16.799171Z","iopub.status.idle":"2025-05-16T15:26:44.827659Z","shell.execute_reply.started":"2025-05-16T15:26:16.799136Z","shell.execute_reply":"2025-05-16T15:26:44.827057Z"}},"outputs":[{"name":"stderr","text":"2025-05-16 15:26:31.132141: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747409191.331295      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747409191.391854      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T15:26:44.828381Z","iopub.execute_input":"2025-05-16T15:26:44.828629Z","iopub.status.idle":"2025-05-16T15:26:44.852120Z","shell.execute_reply.started":"2025-05-16T15:26:44.828609Z","shell.execute_reply":"2025-05-16T15:26:44.851367Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                              image_path  \\\n9743   /kaggle/input/abo-dataset/images/small/28/2881...   \n31595  /kaggle/input/abo-dataset/images/small/30/3020...   \n28281  /kaggle/input/abo-dataset/images/small/52/52e2...   \n42139  /kaggle/input/abo-dataset/images/small/56/5678...   \n33152  /kaggle/input/abo-dataset/images/small/0f/0fd6...   \n...                                                  ...   \n4523   /kaggle/input/abo-dataset/images/small/c0/c094...   \n7231   /kaggle/input/abo-dataset/images/small/07/07c2...   \n21016  /kaggle/input/abo-dataset/images/small/50/5019...   \n9242   /kaggle/input/abo-dataset/images/small/a2/a2bb...   \n36868  /kaggle/input/abo-dataset/images/small/e8/e820...   \n\n                             question   answer  \n9743                What color is it?     Blue  \n31595      What is the frame made of?     Wood  \n28281           What is in the image?   Handle  \n42139               What color is it?     Gray  \n33152      How many screws are there?      Two  \n...                               ...      ...  \n4523   What is the container made of?  Plastic  \n7231              What is the height?    6.0in  \n21016   What color is the background?     blue  \n9242          How much is the height?     12in  \n36868               What color is it?   Silver  \n\n[9221 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9743</th>\n      <td>/kaggle/input/abo-dataset/images/small/28/2881...</td>\n      <td>What color is it?</td>\n      <td>Blue</td>\n    </tr>\n    <tr>\n      <th>31595</th>\n      <td>/kaggle/input/abo-dataset/images/small/30/3020...</td>\n      <td>What is the frame made of?</td>\n      <td>Wood</td>\n    </tr>\n    <tr>\n      <th>28281</th>\n      <td>/kaggle/input/abo-dataset/images/small/52/52e2...</td>\n      <td>What is in the image?</td>\n      <td>Handle</td>\n    </tr>\n    <tr>\n      <th>42139</th>\n      <td>/kaggle/input/abo-dataset/images/small/56/5678...</td>\n      <td>What color is it?</td>\n      <td>Gray</td>\n    </tr>\n    <tr>\n      <th>33152</th>\n      <td>/kaggle/input/abo-dataset/images/small/0f/0fd6...</td>\n      <td>How many screws are there?</td>\n      <td>Two</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4523</th>\n      <td>/kaggle/input/abo-dataset/images/small/c0/c094...</td>\n      <td>What is the container made of?</td>\n      <td>Plastic</td>\n    </tr>\n    <tr>\n      <th>7231</th>\n      <td>/kaggle/input/abo-dataset/images/small/07/07c2...</td>\n      <td>What is the height?</td>\n      <td>6.0in</td>\n    </tr>\n    <tr>\n      <th>21016</th>\n      <td>/kaggle/input/abo-dataset/images/small/50/5019...</td>\n      <td>What color is the background?</td>\n      <td>blue</td>\n    </tr>\n    <tr>\n      <th>9242</th>\n      <td>/kaggle/input/abo-dataset/images/small/a2/a2bb...</td>\n      <td>How much is the height?</td>\n      <td>12in</td>\n    </tr>\n    <tr>\n      <th>36868</th>\n      <td>/kaggle/input/abo-dataset/images/small/e8/e820...</td>\n      <td>What color is it?</td>\n      <td>Silver</td>\n    </tr>\n  </tbody>\n</table>\n<p>9221 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from datasets import Dataset\n\ntrain_dataset = Dataset.from_pandas(train_df, preserve_index=False)\ntest_dataset = Dataset.from_pandas(test_df, preserve_index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T15:26:44.852896Z","iopub.execute_input":"2025-05-16T15:26:44.853155Z","iopub.status.idle":"2025-05-16T15:26:44.913874Z","shell.execute_reply.started":"2025-05-16T15:26:44.853137Z","shell.execute_reply":"2025-05-16T15:26:44.913338Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"wanted_cols = {\"image_path\", \"question\", \"answer\"}\nfor ds in [train_dataset, test_dataset]:\n    extra_cols = [col for col in ds.column_names if col not in wanted_cols]\n    if extra_cols:\n        ds = ds.remove_columns(extra_cols)\nwanted_cols = {\"image_path\", \"question\", \"answer\"}\nfor ds in [train_dataset, test_dataset]:\n    extra_cols = [col for col in ds.column_names if col not in wanted_cols]\n    if extra_cols:\n        ds = ds.remove_columns(extra_cols)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T15:26:44.914568Z","iopub.execute_input":"2025-05-16T15:26:44.914830Z","iopub.status.idle":"2025-05-16T15:26:44.919576Z","shell.execute_reply.started":"2025-05-16T15:26:44.914802Z","shell.execute_reply":"2025-05-16T15:26:44.918908Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from PIL import Image\nfrom transformers import BlipProcessor\n\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n\ndef transform(batch):\n    images = [Image.open(path).convert(\"RGB\") for path in batch[\"image_path\"]]\n    encoding = processor(\n        images,\n        batch[\"question\"],\n        return_tensors=\"pt\",\n        padding=\"max_length\",\n        truncation=True,\n        max_length=32\n    )\n    labels = processor.tokenizer(\n        batch[\"answer\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=32,\n        return_tensors=\"pt\"\n    ).input_ids\n\n    batch[\"pixel_values\"] = encoding[\"pixel_values\"]\n    batch[\"input_ids\"] = encoding[\"input_ids\"]\n    batch[\"attention_mask\"] = encoding[\"attention_mask\"]\n    batch[\"labels\"] = labels\n    return batch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T15:26:44.921919Z","iopub.execute_input":"2025-05-16T15:26:44.922098Z","iopub.status.idle":"2025-05-16T15:26:46.172508Z","shell.execute_reply.started":"2025-05-16T15:26:44.922083Z","shell.execute_reply":"2025-05-16T15:26:46.171923Z"}},"outputs":[{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc3809f68570461a82d729fe32df7758"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09069b4f3b9a4882bb497d87c475fa72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c93efb2a2704b0f9814cc23c57a0234"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b201612cfe348a083c00f76c2239889"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef7d033d10664737bb3992ff7ab5f005"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train_dataset.set_transform(transform)\ntest_dataset.set_transform(transform)\ntrain_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T15:26:46.173144Z","iopub.execute_input":"2025-05-16T15:26:46.173384Z","iopub.status.idle":"2025-05-16T15:26:46.191193Z","shell.execute_reply.started":"2025-05-16T15:26:46.173365Z","shell.execute_reply":"2025-05-16T15:26:46.190510Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['image_path', 'question', 'answer'],\n    num_rows: 36883\n})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from transformers import BlipForQuestionAnswering\nfrom peft import LoraConfig, get_peft_model\n\nmodel = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    target_modules=[\"query\", \"key\", \"value\", \"fc1\", \"fc2\"],  # Adjust if needed after inspecting model.named_modules()\n)\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T15:26:46.191981Z","iopub.execute_input":"2025-05-16T15:26:46.192209Z","iopub.status.idle":"2025-05-16T15:26:54.285640Z","shell.execute_reply.started":"2025-05-16T15:26:46.192193Z","shell.execute_reply":"2025-05-16T15:26:54.284981Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2057ba54383f48b38b81d40fcf8435c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94b1cce7639c43909e19d98e9260a31c"}},"metadata":{}},{"name":"stdout","text":"trainable params: 2,506,752 || all params: 387,179,324 || trainable%: 0.6474\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./blip-lora-vqa\",\n    per_device_train_batch_size=4,   # Lower if you have OOM errors\n    per_device_eval_batch_size=4,\n    num_train_epochs=3,\n    fp16=True,\n    learning_rate=1e-4,\n    logging_steps=50,\n    remove_unused_columns=False,\n    report_to=\"none\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T15:26:54.286455Z","iopub.execute_input":"2025-05-16T15:26:54.286752Z","iopub.status.idle":"2025-05-16T15:26:54.319926Z","shell.execute_reply.started":"2025-05-16T15:26:54.286726Z","shell.execute_reply":"2025-05-16T15:26:54.319391Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    # tokenizer=processor,  # Optional, warning may appear but can be ignored for now\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T15:26:54.320637Z","iopub.execute_input":"2025-05-16T15:26:54.320882Z","iopub.status.idle":"2025-05-16T15:26:55.057690Z","shell.execute_reply.started":"2025-05-16T15:26:54.320866Z","shell.execute_reply":"2025-05-16T15:26:55.056946Z"}},"outputs":[{"name":"stderr","text":"No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"train_results = trainer.train()\ntrainer.save_model(\"./blip-lora-vqa-final\")\neval_results = trainer.evaluate()\nprint(f\"Final evaluation results: {eval_results}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T15:26:55.058534Z","iopub.execute_input":"2025-05-16T15:26:55.058784Z","iopub.status.idle":"2025-05-16T19:58:21.657210Z","shell.execute_reply.started":"2025-05-16T15:26:55.058756Z","shell.execute_reply":"2025-05-16T19:58:21.656611Z"}},"outputs":[{"name":"stderr","text":"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\nWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='13833' max='13833' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [13833/13833 4:20:16, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>9.602000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>8.758200</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>8.454200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>8.330700</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>8.272700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>8.255500</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>8.227600</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>8.236400</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>8.223900</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>8.210500</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>8.204300</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>8.210000</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>8.191600</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>8.199800</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>8.192800</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>8.188500</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>8.201800</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>8.194600</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>8.190700</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>8.202100</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>8.179000</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>8.195300</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>8.195400</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>8.171200</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>8.179100</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>8.181200</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>8.180300</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>8.175800</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>8.179900</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>8.178600</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>8.175700</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>8.192200</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>8.182100</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>8.184800</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>8.179700</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>8.160100</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>8.164800</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>8.170100</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>8.181900</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>8.178200</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>8.172400</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>8.165200</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>8.176300</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>8.176300</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>8.173900</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>8.168700</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>8.172000</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>8.176900</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>8.176400</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>8.173000</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>8.176600</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>8.169000</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>8.178900</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>8.177900</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>8.168000</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>8.173800</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>8.169200</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>8.163900</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>8.162900</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>8.172800</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>8.168900</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>8.166200</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>8.164500</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>8.176500</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>8.174000</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>8.162500</td>\n    </tr>\n    <tr>\n      <td>3350</td>\n      <td>8.164800</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>8.172200</td>\n    </tr>\n    <tr>\n      <td>3450</td>\n      <td>8.170600</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>8.176500</td>\n    </tr>\n    <tr>\n      <td>3550</td>\n      <td>8.175700</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>8.171800</td>\n    </tr>\n    <tr>\n      <td>3650</td>\n      <td>8.165100</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>8.174300</td>\n    </tr>\n    <tr>\n      <td>3750</td>\n      <td>8.172600</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>8.155800</td>\n    </tr>\n    <tr>\n      <td>3850</td>\n      <td>8.161200</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>8.167600</td>\n    </tr>\n    <tr>\n      <td>3950</td>\n      <td>8.167900</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>8.161500</td>\n    </tr>\n    <tr>\n      <td>4050</td>\n      <td>8.161500</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>8.175800</td>\n    </tr>\n    <tr>\n      <td>4150</td>\n      <td>8.171300</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>8.163500</td>\n    </tr>\n    <tr>\n      <td>4250</td>\n      <td>8.175500</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>8.151800</td>\n    </tr>\n    <tr>\n      <td>4350</td>\n      <td>8.157200</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>8.165600</td>\n    </tr>\n    <tr>\n      <td>4450</td>\n      <td>8.169700</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>8.161200</td>\n    </tr>\n    <tr>\n      <td>4550</td>\n      <td>8.165200</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>8.158400</td>\n    </tr>\n    <tr>\n      <td>4650</td>\n      <td>8.171200</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>8.152500</td>\n    </tr>\n    <tr>\n      <td>4750</td>\n      <td>8.158000</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>8.151200</td>\n    </tr>\n    <tr>\n      <td>4850</td>\n      <td>8.144800</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>8.166000</td>\n    </tr>\n    <tr>\n      <td>4950</td>\n      <td>8.148700</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>8.162100</td>\n    </tr>\n    <tr>\n      <td>5050</td>\n      <td>8.153300</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>8.162200</td>\n    </tr>\n    <tr>\n      <td>5150</td>\n      <td>8.159600</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>8.151800</td>\n    </tr>\n    <tr>\n      <td>5250</td>\n      <td>8.163000</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>8.143700</td>\n    </tr>\n    <tr>\n      <td>5350</td>\n      <td>8.150100</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>8.159900</td>\n    </tr>\n    <tr>\n      <td>5450</td>\n      <td>8.168200</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>8.159200</td>\n    </tr>\n    <tr>\n      <td>5550</td>\n      <td>8.141000</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>8.150200</td>\n    </tr>\n    <tr>\n      <td>5650</td>\n      <td>8.152700</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>8.149700</td>\n    </tr>\n    <tr>\n      <td>5750</td>\n      <td>8.157700</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>8.162500</td>\n    </tr>\n    <tr>\n      <td>5850</td>\n      <td>8.155900</td>\n    </tr>\n    <tr>\n      <td>5900</td>\n      <td>8.157800</td>\n    </tr>\n    <tr>\n      <td>5950</td>\n      <td>8.153300</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>8.148200</td>\n    </tr>\n    <tr>\n      <td>6050</td>\n      <td>8.145600</td>\n    </tr>\n    <tr>\n      <td>6100</td>\n      <td>8.161100</td>\n    </tr>\n    <tr>\n      <td>6150</td>\n      <td>8.145000</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>8.154500</td>\n    </tr>\n    <tr>\n      <td>6250</td>\n      <td>8.141800</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>8.150400</td>\n    </tr>\n    <tr>\n      <td>6350</td>\n      <td>8.151600</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>8.147900</td>\n    </tr>\n    <tr>\n      <td>6450</td>\n      <td>8.152900</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>8.153200</td>\n    </tr>\n    <tr>\n      <td>6550</td>\n      <td>8.157900</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>8.154000</td>\n    </tr>\n    <tr>\n      <td>6650</td>\n      <td>8.149600</td>\n    </tr>\n    <tr>\n      <td>6700</td>\n      <td>8.147800</td>\n    </tr>\n    <tr>\n      <td>6750</td>\n      <td>8.162500</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>8.167800</td>\n    </tr>\n    <tr>\n      <td>6850</td>\n      <td>8.150900</td>\n    </tr>\n    <tr>\n      <td>6900</td>\n      <td>8.160000</td>\n    </tr>\n    <tr>\n      <td>6950</td>\n      <td>8.160900</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>8.150700</td>\n    </tr>\n    <tr>\n      <td>7050</td>\n      <td>8.155100</td>\n    </tr>\n    <tr>\n      <td>7100</td>\n      <td>8.158500</td>\n    </tr>\n    <tr>\n      <td>7150</td>\n      <td>8.152900</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>8.154600</td>\n    </tr>\n    <tr>\n      <td>7250</td>\n      <td>8.154500</td>\n    </tr>\n    <tr>\n      <td>7300</td>\n      <td>8.149700</td>\n    </tr>\n    <tr>\n      <td>7350</td>\n      <td>8.155800</td>\n    </tr>\n    <tr>\n      <td>7400</td>\n      <td>8.146400</td>\n    </tr>\n    <tr>\n      <td>7450</td>\n      <td>8.164000</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>8.162900</td>\n    </tr>\n    <tr>\n      <td>7550</td>\n      <td>8.166400</td>\n    </tr>\n    <tr>\n      <td>7600</td>\n      <td>8.167900</td>\n    </tr>\n    <tr>\n      <td>7650</td>\n      <td>8.160300</td>\n    </tr>\n    <tr>\n      <td>7700</td>\n      <td>8.154700</td>\n    </tr>\n    <tr>\n      <td>7750</td>\n      <td>8.140500</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>8.150900</td>\n    </tr>\n    <tr>\n      <td>7850</td>\n      <td>8.154400</td>\n    </tr>\n    <tr>\n      <td>7900</td>\n      <td>8.155600</td>\n    </tr>\n    <tr>\n      <td>7950</td>\n      <td>8.145700</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>8.156000</td>\n    </tr>\n    <tr>\n      <td>8050</td>\n      <td>8.146700</td>\n    </tr>\n    <tr>\n      <td>8100</td>\n      <td>8.144300</td>\n    </tr>\n    <tr>\n      <td>8150</td>\n      <td>8.153700</td>\n    </tr>\n    <tr>\n      <td>8200</td>\n      <td>8.161600</td>\n    </tr>\n    <tr>\n      <td>8250</td>\n      <td>8.150900</td>\n    </tr>\n    <tr>\n      <td>8300</td>\n      <td>8.158700</td>\n    </tr>\n    <tr>\n      <td>8350</td>\n      <td>8.155300</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>8.145100</td>\n    </tr>\n    <tr>\n      <td>8450</td>\n      <td>8.154600</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>8.148200</td>\n    </tr>\n    <tr>\n      <td>8550</td>\n      <td>8.155500</td>\n    </tr>\n    <tr>\n      <td>8600</td>\n      <td>8.141000</td>\n    </tr>\n    <tr>\n      <td>8650</td>\n      <td>8.155900</td>\n    </tr>\n    <tr>\n      <td>8700</td>\n      <td>8.145000</td>\n    </tr>\n    <tr>\n      <td>8750</td>\n      <td>8.153300</td>\n    </tr>\n    <tr>\n      <td>8800</td>\n      <td>8.155200</td>\n    </tr>\n    <tr>\n      <td>8850</td>\n      <td>8.155300</td>\n    </tr>\n    <tr>\n      <td>8900</td>\n      <td>8.154500</td>\n    </tr>\n    <tr>\n      <td>8950</td>\n      <td>8.153500</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>8.139400</td>\n    </tr>\n    <tr>\n      <td>9050</td>\n      <td>8.155000</td>\n    </tr>\n    <tr>\n      <td>9100</td>\n      <td>8.142700</td>\n    </tr>\n    <tr>\n      <td>9150</td>\n      <td>8.135300</td>\n    </tr>\n    <tr>\n      <td>9200</td>\n      <td>8.153300</td>\n    </tr>\n    <tr>\n      <td>9250</td>\n      <td>8.141800</td>\n    </tr>\n    <tr>\n      <td>9300</td>\n      <td>8.148300</td>\n    </tr>\n    <tr>\n      <td>9350</td>\n      <td>8.131000</td>\n    </tr>\n    <tr>\n      <td>9400</td>\n      <td>8.129600</td>\n    </tr>\n    <tr>\n      <td>9450</td>\n      <td>8.136900</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>8.140400</td>\n    </tr>\n    <tr>\n      <td>9550</td>\n      <td>8.144600</td>\n    </tr>\n    <tr>\n      <td>9600</td>\n      <td>8.148900</td>\n    </tr>\n    <tr>\n      <td>9650</td>\n      <td>8.152400</td>\n    </tr>\n    <tr>\n      <td>9700</td>\n      <td>8.154500</td>\n    </tr>\n    <tr>\n      <td>9750</td>\n      <td>8.133600</td>\n    </tr>\n    <tr>\n      <td>9800</td>\n      <td>8.143700</td>\n    </tr>\n    <tr>\n      <td>9850</td>\n      <td>8.137900</td>\n    </tr>\n    <tr>\n      <td>9900</td>\n      <td>8.136700</td>\n    </tr>\n    <tr>\n      <td>9950</td>\n      <td>8.144500</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>8.150900</td>\n    </tr>\n    <tr>\n      <td>10050</td>\n      <td>8.138300</td>\n    </tr>\n    <tr>\n      <td>10100</td>\n      <td>8.144600</td>\n    </tr>\n    <tr>\n      <td>10150</td>\n      <td>8.131100</td>\n    </tr>\n    <tr>\n      <td>10200</td>\n      <td>8.140800</td>\n    </tr>\n    <tr>\n      <td>10250</td>\n      <td>8.139600</td>\n    </tr>\n    <tr>\n      <td>10300</td>\n      <td>8.132200</td>\n    </tr>\n    <tr>\n      <td>10350</td>\n      <td>8.137600</td>\n    </tr>\n    <tr>\n      <td>10400</td>\n      <td>8.145300</td>\n    </tr>\n    <tr>\n      <td>10450</td>\n      <td>8.141800</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>8.146500</td>\n    </tr>\n    <tr>\n      <td>10550</td>\n      <td>8.132600</td>\n    </tr>\n    <tr>\n      <td>10600</td>\n      <td>8.154400</td>\n    </tr>\n    <tr>\n      <td>10650</td>\n      <td>8.133600</td>\n    </tr>\n    <tr>\n      <td>10700</td>\n      <td>8.143500</td>\n    </tr>\n    <tr>\n      <td>10750</td>\n      <td>8.148900</td>\n    </tr>\n    <tr>\n      <td>10800</td>\n      <td>8.150400</td>\n    </tr>\n    <tr>\n      <td>10850</td>\n      <td>8.130200</td>\n    </tr>\n    <tr>\n      <td>10900</td>\n      <td>8.139800</td>\n    </tr>\n    <tr>\n      <td>10950</td>\n      <td>8.142700</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>8.130100</td>\n    </tr>\n    <tr>\n      <td>11050</td>\n      <td>8.137200</td>\n    </tr>\n    <tr>\n      <td>11100</td>\n      <td>8.144400</td>\n    </tr>\n    <tr>\n      <td>11150</td>\n      <td>8.139100</td>\n    </tr>\n    <tr>\n      <td>11200</td>\n      <td>8.135600</td>\n    </tr>\n    <tr>\n      <td>11250</td>\n      <td>8.151300</td>\n    </tr>\n    <tr>\n      <td>11300</td>\n      <td>8.127600</td>\n    </tr>\n    <tr>\n      <td>11350</td>\n      <td>8.153600</td>\n    </tr>\n    <tr>\n      <td>11400</td>\n      <td>8.147200</td>\n    </tr>\n    <tr>\n      <td>11450</td>\n      <td>8.146000</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>8.143900</td>\n    </tr>\n    <tr>\n      <td>11550</td>\n      <td>8.123000</td>\n    </tr>\n    <tr>\n      <td>11600</td>\n      <td>8.140900</td>\n    </tr>\n    <tr>\n      <td>11650</td>\n      <td>8.150300</td>\n    </tr>\n    <tr>\n      <td>11700</td>\n      <td>8.136200</td>\n    </tr>\n    <tr>\n      <td>11750</td>\n      <td>8.142200</td>\n    </tr>\n    <tr>\n      <td>11800</td>\n      <td>8.147700</td>\n    </tr>\n    <tr>\n      <td>11850</td>\n      <td>8.142500</td>\n    </tr>\n    <tr>\n      <td>11900</td>\n      <td>8.153000</td>\n    </tr>\n    <tr>\n      <td>11950</td>\n      <td>8.122400</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>8.131500</td>\n    </tr>\n    <tr>\n      <td>12050</td>\n      <td>8.140300</td>\n    </tr>\n    <tr>\n      <td>12100</td>\n      <td>8.146000</td>\n    </tr>\n    <tr>\n      <td>12150</td>\n      <td>8.153800</td>\n    </tr>\n    <tr>\n      <td>12200</td>\n      <td>8.136900</td>\n    </tr>\n    <tr>\n      <td>12250</td>\n      <td>8.142700</td>\n    </tr>\n    <tr>\n      <td>12300</td>\n      <td>8.134000</td>\n    </tr>\n    <tr>\n      <td>12350</td>\n      <td>8.135400</td>\n    </tr>\n    <tr>\n      <td>12400</td>\n      <td>8.151300</td>\n    </tr>\n    <tr>\n      <td>12450</td>\n      <td>8.150600</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>8.145100</td>\n    </tr>\n    <tr>\n      <td>12550</td>\n      <td>8.139500</td>\n    </tr>\n    <tr>\n      <td>12600</td>\n      <td>8.140800</td>\n    </tr>\n    <tr>\n      <td>12650</td>\n      <td>8.157700</td>\n    </tr>\n    <tr>\n      <td>12700</td>\n      <td>8.145900</td>\n    </tr>\n    <tr>\n      <td>12750</td>\n      <td>8.136100</td>\n    </tr>\n    <tr>\n      <td>12800</td>\n      <td>8.148900</td>\n    </tr>\n    <tr>\n      <td>12850</td>\n      <td>8.141700</td>\n    </tr>\n    <tr>\n      <td>12900</td>\n      <td>8.145100</td>\n    </tr>\n    <tr>\n      <td>12950</td>\n      <td>8.149400</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>8.143500</td>\n    </tr>\n    <tr>\n      <td>13050</td>\n      <td>8.141700</td>\n    </tr>\n    <tr>\n      <td>13100</td>\n      <td>8.129900</td>\n    </tr>\n    <tr>\n      <td>13150</td>\n      <td>8.140600</td>\n    </tr>\n    <tr>\n      <td>13200</td>\n      <td>8.144900</td>\n    </tr>\n    <tr>\n      <td>13250</td>\n      <td>8.132300</td>\n    </tr>\n    <tr>\n      <td>13300</td>\n      <td>8.139400</td>\n    </tr>\n    <tr>\n      <td>13350</td>\n      <td>8.144100</td>\n    </tr>\n    <tr>\n      <td>13400</td>\n      <td>8.147500</td>\n    </tr>\n    <tr>\n      <td>13450</td>\n      <td>8.150500</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>8.145900</td>\n    </tr>\n    <tr>\n      <td>13550</td>\n      <td>8.136500</td>\n    </tr>\n    <tr>\n      <td>13600</td>\n      <td>8.153000</td>\n    </tr>\n    <tr>\n      <td>13650</td>\n      <td>8.135700</td>\n    </tr>\n    <tr>\n      <td>13700</td>\n      <td>8.141900</td>\n    </tr>\n    <tr>\n      <td>13750</td>\n      <td>8.149500</td>\n    </tr>\n    <tr>\n      <td>13800</td>\n      <td>8.139100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1153' max='1153' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1153/1153 11:05]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Final evaluation results: {'eval_runtime': 666.1398, 'eval_samples_per_second': 13.842, 'eval_steps_per_second': 1.731, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import os\n\nmodel_dir = \"./blip-lora-vqa-final\"\nprint(\"Directory exists:\", os.path.exists(model_dir))\nprint(\"Contents:\", os.listdir(model_dir) if os.path.exists(model_dir) else \"N/A\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:59:43.848100Z","iopub.execute_input":"2025-05-16T19:59:43.848831Z","iopub.status.idle":"2025-05-16T19:59:43.853877Z","shell.execute_reply.started":"2025-05-16T19:59:43.848800Z","shell.execute_reply":"2025-05-16T19:59:43.853253Z"}},"outputs":[{"name":"stdout","text":"Directory exists: True\nContents: ['README.md', 'training_args.bin', 'adapter_model.safetensors', 'adapter_config.json']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!zip -r -s 300m /kaggle/working/blip-lora-vqa-split.zip /kaggle/working/blip-lora-vqa\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:59:48.757173Z","iopub.execute_input":"2025-05-16T19:59:48.758038Z","iopub.status.idle":"2025-05-16T20:00:28.283036Z","shell.execute_reply.started":"2025-05-16T19:59:48.758012Z","shell.execute_reply":"2025-05-16T20:00:28.282328Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/blip-lora-vqa/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10000/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10000/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10000/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10000/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10000/trainer_state.json (deflated 79%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10000/adapter_model.safetensors","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10000/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10000/scheduler.pt (deflated 55%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10000/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6000/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6000/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6000/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6000/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6000/trainer_state.json (deflated 78%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6000/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6000/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6000/scheduler.pt (deflated 55%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6000/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12500/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12500/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12500/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12500/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12500/trainer_state.json (deflated 80%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12500/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12500/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12500/scheduler.pt (deflated 55%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12500/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13000/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13000/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13000/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13000/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13000/trainer_state.json (deflated 80%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13000/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13000/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13000/scheduler.pt (deflated 56%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13000/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9000/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9000/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9000/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9000/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9000/trainer_state.json (deflated 79%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9000/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9000/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9000/scheduler.pt (deflated 56%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9000/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11000/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11000/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11000/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11000/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11000/trainer_state.json (deflated 80%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11000/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11000/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11000/scheduler.pt (deflated 56%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11000/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12000/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12000/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12000/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12000/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12000/trainer_state.json (deflated 80%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12000/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12000/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12000/scheduler.pt (deflated 55%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-12000/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5000/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5000/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5000/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5000/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5000/trainer_state.json (deflated 78%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5000/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5000/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5000/scheduler.pt (deflated 56%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5000/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4000/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4000/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4000/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4000/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4000/trainer_state.json (deflated 78%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4000/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4000/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4000/scheduler.pt (deflated 55%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4000/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7000/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7000/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7000/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7000/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7000/trainer_state.json (deflated 79%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7000/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7000/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7000/scheduler.pt (deflated 55%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7000/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11500/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11500/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11500/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11500/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11500/trainer_state.json (deflated 80%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11500/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11500/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11500/scheduler.pt (deflated 55%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-11500/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5500/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5500/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5500/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5500/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5500/trainer_state.json (deflated 78%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5500/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5500/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5500/scheduler.pt (deflated 56%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-5500/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-500/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-500/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-500/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-500/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-500/trainer_state.json (deflated 68%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-500/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-500/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-500/scheduler.pt (deflated 55%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-500/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3000/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3000/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3000/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3000/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3000/trainer_state.json (deflated 77%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3000/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3000/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3000/scheduler.pt (deflated 55%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3000/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6500/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6500/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6500/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6500/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6500/trainer_state.json (deflated 78%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6500/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6500/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6500/scheduler.pt (deflated 55%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-6500/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13833/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13833/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13833/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13833/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13833/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13833/trainer_state.json (deflated 80%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13833/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13833/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13833/scheduler.pt (deflated 56%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13833/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2500/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2500/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2500/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2500/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2500/trainer_state.json (deflated 76%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2500/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2500/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2500/scheduler.pt (deflated 56%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2500/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10500/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10500/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10500/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10500/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10500/trainer_state.json (deflated 79%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10500/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10500/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10500/scheduler.pt (deflated 56%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-10500/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7500/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7500/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7500/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7500/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7500/trainer_state.json (deflated 79%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7500/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7500/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7500/scheduler.pt (deflated 55%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-7500/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2000/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2000/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2000/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2000/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2000/trainer_state.json (deflated 75%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2000/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2000/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2000/scheduler.pt (deflated 56%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-2000/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8000/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8000/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8000/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8000/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8000/trainer_state.json (deflated 79%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8000/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8000/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8000/scheduler.pt (deflated 56%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8000/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3500/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3500/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3500/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3500/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3500/trainer_state.json (deflated 77%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3500/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3500/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3500/scheduler.pt (deflated 56%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-3500/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4500/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4500/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4500/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4500/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4500/trainer_state.json (deflated 78%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4500/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4500/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4500/scheduler.pt (deflated 55%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-4500/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1500/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1500/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1500/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1500/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1500/trainer_state.json (deflated 74%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1500/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1500/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1500/scheduler.pt (deflated 55%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1500/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13500/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13500/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13500/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13500/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13500/trainer_state.json (deflated 80%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13500/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13500/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13500/scheduler.pt (deflated 55%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-13500/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1000/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1000/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1000/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1000/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1000/trainer_state.json (deflated 72%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1000/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1000/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1000/scheduler.pt (deflated 55%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-1000/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9500/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9500/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9500/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9500/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9500/trainer_state.json (deflated 79%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9500/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9500/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9500/scheduler.pt (deflated 56%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-9500/adapter_config.json (deflated 54%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8500/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8500/scaler.pt (deflated 60%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8500/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8500/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8500/trainer_state.json (deflated 79%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8500/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8500/optimizer.pt (deflated 8%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8500/scheduler.pt (deflated 56%)\n  adding: kaggle/working/blip-lora-vqa/checkpoint-8500/adapter_config.json (deflated 54%)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!zip -r /kaggle/working/blip-lora-vqa-final.zip /kaggle/working/blip-lora-vqa-final\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T20:02:57.085348Z","iopub.execute_input":"2025-05-16T20:02:57.085725Z","iopub.status.idle":"2025-05-16T20:02:57.794696Z","shell.execute_reply.started":"2025-05-16T20:02:57.085696Z","shell.execute_reply":"2025-05-16T20:02:57.793756Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/blip-lora-vqa-final/ (stored 0%)\n  adding: kaggle/working/blip-lora-vqa-final/README.md (deflated 66%)\n  adding: kaggle/working/blip-lora-vqa-final/training_args.bin (deflated 52%)\n  adding: kaggle/working/blip-lora-vqa-final/adapter_model.safetensors","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 7%)\n  adding: kaggle/working/blip-lora-vqa-final/adapter_config.json (deflated 54%)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import torch\nfrom transformers import BlipForQuestionAnswering, BlipProcessor\nfrom PIL import Image\n\n# Load model and processor\nmodel_1 = BlipForQuestionAnswering.from_pretrained(\"./blip-lora-vqa-final\")\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_1 = model_1.to(device)\nmodel_1.eval()\n\n# Preview predictions for the first 10 rows\nfor idx, row in test_df.head(10).iterrows():\n    image = Image.open(row['image_path']).convert('RGB')\n    question = row['question']\n    true_answer = row['answer']\n\n    # Preprocess\n    inputs = processor(image, question, return_tensors=\"pt\").to(device)\n\n    # Generate prediction\n    with torch.no_grad():\n        out = model_1.generate(**inputs)\n    predicted_answer = processor.decode(out[0], skip_special_tokens=True)\n\n    print(f\"Row {idx}:\")\n    print(f\"  Question: {question}\")\n    print(f\"  True Answer: {true_answer}\")\n    print(f\"  Predicted Answer: {predicted_answer}\")\n    print(\"-\" * 50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T20:00:28.284753Z","iopub.execute_input":"2025-05-16T20:00:28.284975Z","iopub.status.idle":"2025-05-16T20:00:32.499700Z","shell.execute_reply.started":"2025-05-16T20:00:28.284956Z","shell.execute_reply":"2025-05-16T20:00:32.498956Z"}},"outputs":[{"name":"stdout","text":"Row 9743:\n  Question: What color is it?\n  True Answer: Blue\n  Predicted Answer: blue\n--------------------------------------------------\nRow 31595:\n  Question: What is the frame made of?\n  True Answer: Wood\n  Predicted Answer: wood\n--------------------------------------------------\nRow 28281:\n  Question: What is in the image?\n  True Answer: Handle\n  Predicted Answer: handle\n--------------------------------------------------\nRow 42139:\n  Question: What color is it?\n  True Answer: Gray\n  Predicted Answer: grey\n--------------------------------------------------\nRow 33152:\n  Question: How many screws are there?\n  True Answer: Two\n  Predicted Answer: two\n--------------------------------------------------\nRow 28154:\n  Question: What is the height?\n  True Answer: 96cm\n  Predicted Answer: 85cm\n--------------------------------------------------\nRow 39757:\n  Question: What color is the case?\n  True Answer: Pink\n  Predicted Answer: pink\n--------------------------------------------------\nRow 19645:\n  Question: What color is the fixture?\n  True Answer: Black\n  Predicted Answer: black\n--------------------------------------------------\nRow 35076:\n  Question: What is in the image?\n  True Answer: Ingredients\n  Predicted Answer: ingredients\n--------------------------------------------------\nRow 39489:\n  Question: What is in the image?\n  True Answer: ring\n  Predicted Answer: case\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import time\nimport torch\nfrom transformers import BlipForQuestionAnswering, BlipProcessor\nfrom PIL import Image\n\n# Start timing\nstart_time = time.time()\n\n# 1. Load your fine-tuned model and processor\nmodel_1 = BlipForQuestionAnswering.from_pretrained(\"./blip-lora-vqa-final\")\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n\n# 2. Move model to device (CPU or CUDA)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_1 = model_1.to(device)\nmodel_1.eval()\n\n# 3. Loop over your test DataFrame and generate answers\npred_answers = []\n\nfor idx, row in test_df.iterrows():\n    image = Image.open(row['image_path']).convert('RGB')\n    question = row['question']\n\n    # Preprocess inputs\n    inputs = processor(image, question, return_tensors=\"pt\").to(device)\n\n    # Generate answer\n    with torch.no_grad():\n        out = model_1.generate(**inputs)\n    answer = processor.decode(out[0], skip_special_tokens=True)\n    pred_answers.append(answer)\n\n# 4. Add predictions to your DataFrame as a new column\ntest_df['predicted_answer'] = pred_answers\n\n# End timing\nend_time = time.time()\nelapsed_time = end_time - start_time\n\n# 5. Display or save results\nprint(test_df[['image_path', 'question', 'answer', 'predicted_answer']].head())\nprint(f\"\\n⏱️ Total time taken: {elapsed_time:.2f} seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T20:06:34.089181Z","iopub.execute_input":"2025-05-16T20:06:34.089517Z","iopub.status.idle":"2025-05-16T20:24:50.474552Z","shell.execute_reply.started":"2025-05-16T20:06:34.089489Z","shell.execute_reply":"2025-05-16T20:24:50.473712Z"}},"outputs":[{"name":"stdout","text":"                                              image_path  \\\n9743   /kaggle/input/abo-dataset/images/small/28/2881...   \n31595  /kaggle/input/abo-dataset/images/small/30/3020...   \n28281  /kaggle/input/abo-dataset/images/small/52/52e2...   \n42139  /kaggle/input/abo-dataset/images/small/56/5678...   \n33152  /kaggle/input/abo-dataset/images/small/0f/0fd6...   \n\n                         question  answer predicted_answer  \n9743            What color is it?    Blue             blue  \n31595  What is the frame made of?    Wood             wood  \n28281       What is in the image?  Handle           handle  \n42139           What color is it?    Gray             grey  \n33152  How many screws are there?     Two              two  \n\n⏱️ Total time taken: 1096.37 seconds\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Assuming 'test_df' already has columns: 'answer' (ground truth) and 'predicted_answer'\n# We'll add 'is_true' column: 1 if prediction matches ground truth, else 0\n\n# Normalize answers for comparison (optional but recommended)\ndef normalize(text):\n    return str(text).strip().lower()\n\ntest_df['is_true'] = (test_df['predicted_answer'].apply(normalize) == test_df['answer'].apply(normalize)).astype(int)\n\n# Count number of true and false predictions\nnum_true = test_df['is_true'].sum()\nnum_false = len(test_df) - num_true\n\nprint(f\"Number of correct predictions (is_true=1): {num_true}\")\nprint(f\"Number of incorrect predictions (is_true=0): {num_false}\")\n\n# Save to CSV\ntest_df.to_csv('LORS_PRED_8.csv', index=False)\nprint(\"Results saved to LORS_PRED_8.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T20:24:50.475891Z","iopub.execute_input":"2025-05-16T20:24:50.476100Z","iopub.status.idle":"2025-05-16T20:24:50.528299Z","shell.execute_reply.started":"2025-05-16T20:24:50.476084Z","shell.execute_reply":"2025-05-16T20:24:50.527728Z"}},"outputs":[{"name":"stdout","text":"Number of correct predictions (is_true=1): 6066\nNumber of incorrect predictions (is_true=0): 3155\nResults saved to LORS_PRED_8.csv\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"def normalize_answer(s):\n    \"\"\"Normalize answer for more accurate comparison.\"\"\"\n    s = re.sub(r'\\b(a|an|the)\\b', ' ', s.lower())\n    s = re.sub(r'[^\\w\\s]', '', s)\n    s = re.sub(r'\\s+', ' ', s).strip()\n    return s\n\ndef calculate_bertscore(pred, ref, tokenizer, model, device):\n    \"\"\"Calculate BERTScore between prediction and reference.\"\"\"\n    pred_tokens = tokenizer(pred, return_tensors='pt', padding=True, truncation=True).to(device)\n    ref_tokens = tokenizer(ref, return_tensors='pt', padding=True, truncation=True).to(device)\n    \n    with torch.no_grad():\n        pred_outputs = model(**pred_tokens)\n        ref_outputs = model(**ref_tokens)\n    \n    pred_embedding = pred_outputs.last_hidden_state[:, 0, :]\n    ref_embedding = ref_outputs.last_hidden_state[:, 0, :]\n    \n    pred_embedding = pred_embedding / pred_embedding.norm(dim=1, keepdim=True)\n    ref_embedding = ref_embedding / ref_embedding.norm(dim=1, keepdim=True)\n    \n    similarity = torch.matmul(pred_embedding, ref_embedding.transpose(0, 1)).item()\n    return similarity\n\ndef exact_match(pred, ref):\n    \"\"\"Check if prediction exactly matches reference after normalization.\"\"\"\n    return normalize_answer(pred) == normalize_answer(ref)\n\ndef token_match(pred, ref):\n    \"\"\"Check if the tokens in prediction match the reference.\"\"\"\n    pred_tokens = normalize_answer(pred).split()\n    ref_tokens = normalize_answer(ref).split()\n    return Counter(pred_tokens) == Counter(ref_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T20:28:24.315831Z","iopub.execute_input":"2025-05-16T20:28:24.316108Z","iopub.status.idle":"2025-05-16T20:28:24.323181Z","shell.execute_reply.started":"2025-05-16T20:28:24.316084Z","shell.execute_reply":"2025-05-16T20:28:24.322344Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nimport torch\n\n# Load pretrained BERT model and tokenizer\nbert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nbert_model = AutoModel.from_pretrained(\"bert-base-uncased\").to(device)\nbert_model.eval()\n\n# Compute BERTScore for each prediction-reference pair\nbert_scores = []\nfor pred, ref in zip(test_df['predicted_answer'], test_df['answer']):\n    pred = str(pred)\n    ref = str(ref)\n    score = calculate_bertscore(pred, ref, bert_tokenizer, bert_model, device)\n    bert_scores.append(score)\n\n# Add BERTScore column to DataFrame\ntest_df['bertscore'] = bert_scores\n\n# Print average BERTScore\nprint(f\"📊 Average BERTScore: {sum(bert_scores) / len(bert_scores):.4f}\")\n\n# (Optional) Save the results to CSV\ntest_df.to_csv(\"LORA_PRED_8_with_bertscore.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T20:35:19.150025Z","iopub.execute_input":"2025-05-16T20:35:19.150674Z","iopub.status.idle":"2025-05-16T20:37:49.656251Z","shell.execute_reply.started":"2025-05-16T20:35:19.150649Z","shell.execute_reply":"2025-05-16T20:37:49.655637Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"388319ca63044cecb938d07fe310dfe0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb1f8d10d8984b8f9600f35cdc1d4d1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b92a73b3015d49c9a48c23e0e7b9c898"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b6cc7210b0349fbb65faac7e340e690"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0493f7e0393e4277a02673832e2b042d"}},"metadata":{}},{"name":"stdout","text":"📊 Average BERTScore: 0.9751\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\n\n# Load CSV file\ndf = pd.read_csv(\"/kaggle/input/lora-pred-16/LORS_PRED_16.csv\")\n\n# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load BERT tokenizer and model\nbert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nbert_model = AutoModel.from_pretrained(\"bert-base-uncased\").to(device)\nbert_model.eval()\n\n# BERTScore function (same as yours)\ndef calculate_bertscore(pred, ref, tokenizer, model, device):\n    pred_tokens = tokenizer(pred, return_tensors='pt', padding=True, truncation=True).to(device)\n    ref_tokens = tokenizer(ref, return_tensors='pt', padding=True, truncation=True).to(device)\n\n    with torch.no_grad():\n        pred_outputs = model(**pred_tokens)\n        ref_outputs = model(**ref_tokens)\n\n    pred_embedding = pred_outputs.last_hidden_state[:, 0, :]\n    ref_embedding = ref_outputs.last_hidden_state[:, 0, :]\n\n    pred_embedding = pred_embedding / pred_embedding.norm(dim=1, keepdim=True)\n    ref_embedding = ref_embedding / ref_embedding.norm(dim=1, keepdim=True)\n\n    similarity = torch.matmul(pred_embedding, ref_embedding.transpose(0, 1)).item()\n    return similarity\n\n# Compute BERTScores\nbert_scores = []\nfor pred, ref in zip(df['predicted_answer'], df['answer']):\n    pred = str(pred)\n    ref = str(ref)\n    score = calculate_bertscore(pred, ref, bert_tokenizer, bert_model, device)\n    bert_scores.append(score)\n\n# Add to DataFrame\ndf['bertscore'] = bert_scores\n\n# Print average BERTScore\nprint(f\"📊 Average BERTScore: {sum(bert_scores) / len(bert_scores):.4f}\")\n\n# Save result (optional)\ndf.to_csv(\"LORA_PRED_16_with_bertscore.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T20:38:42.337518Z","iopub.execute_input":"2025-05-16T20:38:42.338085Z","iopub.status.idle":"2025-05-16T20:41:00.931934Z","shell.execute_reply.started":"2025-05-16T20:38:42.338059Z","shell.execute_reply":"2025-05-16T20:41:00.931278Z"}},"outputs":[{"name":"stdout","text":"📊 Average BERTScore: 0.9757\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}