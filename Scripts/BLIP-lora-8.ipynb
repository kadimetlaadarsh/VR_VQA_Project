{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11827247,"sourceType":"datasetVersion","datasetId":7429866},{"sourceId":11827409,"sourceType":"datasetVersion","datasetId":7429981}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets peft scikit-learn pandas pillow\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:33:46.387673Z","iopub.execute_input":"2025-05-15T19:33:46.387830Z","iopub.status.idle":"2025-05-15T19:35:01.472738Z","shell.execute_reply.started":"2025-05-15T19:33:46.387815Z","shell.execute_reply":"2025-05-15T19:35:01.472049Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import Dataset\nimport torch\nfrom transformers import (\n    BlipForQuestionAnswering,\n    BlipProcessor,\n    TrainingArguments,\n    Trainer\n)\nfrom peft import LoraConfig, get_peft_model\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport os\nfrom PIL import Image\n\n# 1. Dataset Preparation -----------------------------------------------\n# Load and flatten your dataset\ndf = pd.read_csv(\"/kaggle/input/merged-one/merged_vqa_dataset_output.csv\")\nBASE_IMAGE_DIR = \"/kaggle/input/abo-dataset/images/small\"\n\n# Flatten into (image_path, question, answer) format\nsamples = []\nfor _, row in df.iterrows():\n    for q_col, a_col in zip(['q1', 'q2', 'q3'], ['a1', 'a2', 'a3']):\n        samples.append({\n            \"image_path\": os.path.join(BASE_IMAGE_DIR, row['path']),\n            \"question\": row[q_col],\n            \"answer\": row[a_col]\n        })\n\n# Split into train/test\ntrain_df, test_df = train_test_split(pd.DataFrame(samples), test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:35:01.474349Z","iopub.execute_input":"2025-05-15T19:35:01.474556Z","iopub.status.idle":"2025-05-15T19:35:29.490673Z","shell.execute_reply.started":"2025-05-15T19:35:01.474535Z","shell.execute_reply":"2025-05-15T19:35:29.490088Z"}},"outputs":[{"name":"stderr","text":"2025-05-15 19:35:15.509927: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747337715.696420      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747337715.748965      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:35:29.491360Z","iopub.execute_input":"2025-05-15T19:35:29.491572Z","iopub.status.idle":"2025-05-15T19:35:29.514310Z","shell.execute_reply.started":"2025-05-15T19:35:29.491555Z","shell.execute_reply":"2025-05-15T19:35:29.513726Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                              image_path  \\\n9743   /kaggle/input/abo-dataset/images/small/28/2881...   \n31595  /kaggle/input/abo-dataset/images/small/30/3020...   \n28281  /kaggle/input/abo-dataset/images/small/52/52e2...   \n42139  /kaggle/input/abo-dataset/images/small/56/5678...   \n33152  /kaggle/input/abo-dataset/images/small/0f/0fd6...   \n...                                                  ...   \n4523   /kaggle/input/abo-dataset/images/small/c0/c094...   \n7231   /kaggle/input/abo-dataset/images/small/07/07c2...   \n21016  /kaggle/input/abo-dataset/images/small/50/5019...   \n9242   /kaggle/input/abo-dataset/images/small/a2/a2bb...   \n36868  /kaggle/input/abo-dataset/images/small/e8/e820...   \n\n                             question   answer  \n9743                What color is it?     Blue  \n31595      What is the frame made of?     Wood  \n28281           What is in the image?   Handle  \n42139               What color is it?     Gray  \n33152      How many screws are there?      Two  \n...                               ...      ...  \n4523   What is the container made of?  Plastic  \n7231              What is the height?    6.0in  \n21016   What color is the background?     blue  \n9242          How much is the height?     12in  \n36868               What color is it?   Silver  \n\n[9221 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9743</th>\n      <td>/kaggle/input/abo-dataset/images/small/28/2881...</td>\n      <td>What color is it?</td>\n      <td>Blue</td>\n    </tr>\n    <tr>\n      <th>31595</th>\n      <td>/kaggle/input/abo-dataset/images/small/30/3020...</td>\n      <td>What is the frame made of?</td>\n      <td>Wood</td>\n    </tr>\n    <tr>\n      <th>28281</th>\n      <td>/kaggle/input/abo-dataset/images/small/52/52e2...</td>\n      <td>What is in the image?</td>\n      <td>Handle</td>\n    </tr>\n    <tr>\n      <th>42139</th>\n      <td>/kaggle/input/abo-dataset/images/small/56/5678...</td>\n      <td>What color is it?</td>\n      <td>Gray</td>\n    </tr>\n    <tr>\n      <th>33152</th>\n      <td>/kaggle/input/abo-dataset/images/small/0f/0fd6...</td>\n      <td>How many screws are there?</td>\n      <td>Two</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4523</th>\n      <td>/kaggle/input/abo-dataset/images/small/c0/c094...</td>\n      <td>What is the container made of?</td>\n      <td>Plastic</td>\n    </tr>\n    <tr>\n      <th>7231</th>\n      <td>/kaggle/input/abo-dataset/images/small/07/07c2...</td>\n      <td>What is the height?</td>\n      <td>6.0in</td>\n    </tr>\n    <tr>\n      <th>21016</th>\n      <td>/kaggle/input/abo-dataset/images/small/50/5019...</td>\n      <td>What color is the background?</td>\n      <td>blue</td>\n    </tr>\n    <tr>\n      <th>9242</th>\n      <td>/kaggle/input/abo-dataset/images/small/a2/a2bb...</td>\n      <td>How much is the height?</td>\n      <td>12in</td>\n    </tr>\n    <tr>\n      <th>36868</th>\n      <td>/kaggle/input/abo-dataset/images/small/e8/e820...</td>\n      <td>What color is it?</td>\n      <td>Silver</td>\n    </tr>\n  </tbody>\n</table>\n<p>9221 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from datasets import Dataset\n\ntrain_dataset = Dataset.from_pandas(train_df, preserve_index=False)\ntest_dataset = Dataset.from_pandas(test_df, preserve_index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:35:29.514993Z","iopub.execute_input":"2025-05-15T19:35:29.515441Z","iopub.status.idle":"2025-05-15T19:35:29.573687Z","shell.execute_reply.started":"2025-05-15T19:35:29.515423Z","shell.execute_reply":"2025-05-15T19:35:29.573145Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"wanted_cols = {\"image_path\", \"question\", \"answer\"}\nfor ds in [train_dataset, test_dataset]:\n    extra_cols = [col for col in ds.column_names if col not in wanted_cols]\n    if extra_cols:\n        ds = ds.remove_columns(extra_cols)\nwanted_cols = {\"image_path\", \"question\", \"answer\"}\nfor ds in [train_dataset, test_dataset]:\n    extra_cols = [col for col in ds.column_names if col not in wanted_cols]\n    if extra_cols:\n        ds = ds.remove_columns(extra_cols)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:35:29.574367Z","iopub.execute_input":"2025-05-15T19:35:29.574538Z","iopub.status.idle":"2025-05-15T19:35:29.579107Z","shell.execute_reply.started":"2025-05-15T19:35:29.574525Z","shell.execute_reply":"2025-05-15T19:35:29.578396Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from PIL import Image\nfrom transformers import BlipProcessor\n\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n\ndef transform(batch):\n    images = [Image.open(path).convert(\"RGB\") for path in batch[\"image_path\"]]\n    encoding = processor(\n        images,\n        batch[\"question\"],\n        return_tensors=\"pt\",\n        padding=\"max_length\",\n        truncation=True,\n        max_length=32\n    )\n    labels = processor.tokenizer(\n        batch[\"answer\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=32,\n        return_tensors=\"pt\"\n    ).input_ids\n\n    batch[\"pixel_values\"] = encoding[\"pixel_values\"]\n    batch[\"input_ids\"] = encoding[\"input_ids\"]\n    batch[\"attention_mask\"] = encoding[\"attention_mask\"]\n    batch[\"labels\"] = labels\n    return batch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:35:29.579867Z","iopub.execute_input":"2025-05-15T19:35:29.580089Z","iopub.status.idle":"2025-05-15T19:35:34.122865Z","shell.execute_reply.started":"2025-05-15T19:35:29.580069Z","shell.execute_reply":"2025-05-15T19:35:34.122116Z"}},"outputs":[{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95277fab32ee4863afd00e5b16e20f2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4fdf186e14d44a6bc1a26292420990a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17ad94ee004d4d28ae6e7db94dcf4707"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ddec7ff62ad412fb1f5cb38d82f5277"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10bd3e9b39a549a6a4778cbb0bd481d7"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"train_dataset.set_transform(transform)\ntest_dataset.set_transform(transform)\ntrain_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:35:34.124916Z","iopub.execute_input":"2025-05-15T19:35:34.125160Z","iopub.status.idle":"2025-05-15T19:35:34.141486Z","shell.execute_reply.started":"2025-05-15T19:35:34.125142Z","shell.execute_reply":"2025-05-15T19:35:34.140785Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['image_path', 'question', 'answer'],\n    num_rows: 36883\n})"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from transformers import BlipForQuestionAnswering\nfrom peft import LoraConfig, get_peft_model\n\nmodel = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    target_modules=[\"query\", \"key\", \"value\", \"fc1\", \"fc2\"],  # Adjust if needed after inspecting model.named_modules()\n)\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:35:34.142155Z","iopub.execute_input":"2025-05-15T19:35:34.142371Z","iopub.status.idle":"2025-05-15T19:35:40.169887Z","shell.execute_reply.started":"2025-05-15T19:35:34.142354Z","shell.execute_reply":"2025-05-15T19:35:40.169125Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a8bc6a9721341a4b5f08c879003c4af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b3eef2be527485698140f5d2e196187"}},"metadata":{}},{"name":"stdout","text":"trainable params: 2,506,752 || all params: 387,179,324 || trainable%: 0.6474\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./blip-lora-vqa\",\n    per_device_train_batch_size=4,   # Lower if you have OOM errors\n    per_device_eval_batch_size=4,\n    num_train_epochs=3,\n    fp16=True,\n    learning_rate=1e-4,\n    logging_steps=50,\n    remove_unused_columns=False,\n    report_to=\"none\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:35:40.170694Z","iopub.execute_input":"2025-05-15T19:35:40.171458Z","iopub.status.idle":"2025-05-15T19:35:40.204505Z","shell.execute_reply.started":"2025-05-15T19:35:40.171432Z","shell.execute_reply":"2025-05-15T19:35:40.203899Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    # tokenizer=processor,  # Optional, warning may appear but can be ignored for now\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:35:40.205435Z","iopub.execute_input":"2025-05-15T19:35:40.205665Z","iopub.status.idle":"2025-05-15T19:35:40.963754Z","shell.execute_reply.started":"2025-05-15T19:35:40.205649Z","shell.execute_reply":"2025-05-15T19:35:40.963019Z"}},"outputs":[{"name":"stderr","text":"No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"train_results = trainer.train()\ntrainer.save_model(\"./blip-lora-vqa-final\")\neval_results = trainer.evaluate()\nprint(f\"Final evaluation results: {eval_results}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:35:40.964535Z","iopub.execute_input":"2025-05-15T19:35:40.964782Z","iopub.status.idle":"2025-05-16T00:09:29.191612Z","shell.execute_reply.started":"2025-05-15T19:35:40.964757Z","shell.execute_reply":"2025-05-16T00:09:29.190861Z"}},"outputs":[{"name":"stderr","text":"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='13833' max='13833' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [13833/13833 4:22:37, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>9.600500</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>8.735600</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>8.427100</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>8.288700</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>8.227400</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>8.207700</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>8.180400</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>8.188900</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>8.174800</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>8.159900</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>8.155700</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>8.161800</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>8.143000</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>8.149500</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>8.141800</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>8.136900</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>8.149100</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>8.143700</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>8.136800</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>8.149200</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>8.128200</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>8.141100</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>8.143300</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>8.121400</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>8.127800</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>8.130900</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>8.127100</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>8.124600</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>8.127600</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>8.126600</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>8.123100</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>8.139000</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>8.126100</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>8.133000</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>8.126700</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>8.108400</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>8.111300</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>8.116700</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>8.128900</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>8.126300</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>8.119800</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>8.111900</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>8.124000</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>8.123400</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>8.117000</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>8.113400</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>8.119500</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>8.123700</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>8.123000</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>8.120200</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>8.122300</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>8.116300</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>8.125400</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>8.124800</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>8.115400</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>8.121300</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>8.113500</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>8.111300</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>8.109000</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>8.117000</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>8.116600</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>8.112400</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>8.111600</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>8.122700</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>8.119600</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>8.110400</td>\n    </tr>\n    <tr>\n      <td>3350</td>\n      <td>8.112300</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>8.117800</td>\n    </tr>\n    <tr>\n      <td>3450</td>\n      <td>8.116300</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>8.124300</td>\n    </tr>\n    <tr>\n      <td>3550</td>\n      <td>8.122400</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>8.117400</td>\n    </tr>\n    <tr>\n      <td>3650</td>\n      <td>8.113200</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>8.120000</td>\n    </tr>\n    <tr>\n      <td>3750</td>\n      <td>8.117000</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>8.103600</td>\n    </tr>\n    <tr>\n      <td>3850</td>\n      <td>8.107200</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>8.114900</td>\n    </tr>\n    <tr>\n      <td>3950</td>\n      <td>8.113500</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>8.106300</td>\n    </tr>\n    <tr>\n      <td>4050</td>\n      <td>8.108300</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>8.121600</td>\n    </tr>\n    <tr>\n      <td>4150</td>\n      <td>8.118000</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>8.109500</td>\n    </tr>\n    <tr>\n      <td>4250</td>\n      <td>8.121600</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>8.097700</td>\n    </tr>\n    <tr>\n      <td>4350</td>\n      <td>8.104400</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>8.111900</td>\n    </tr>\n    <tr>\n      <td>4450</td>\n      <td>8.114700</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>8.107700</td>\n    </tr>\n    <tr>\n      <td>4550</td>\n      <td>8.110600</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>8.104100</td>\n    </tr>\n    <tr>\n      <td>4650</td>\n      <td>8.114300</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>8.098600</td>\n    </tr>\n    <tr>\n      <td>4750</td>\n      <td>8.105700</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>8.098500</td>\n    </tr>\n    <tr>\n      <td>4850</td>\n      <td>8.090300</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>8.109500</td>\n    </tr>\n    <tr>\n      <td>4950</td>\n      <td>8.095200</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>8.105800</td>\n    </tr>\n    <tr>\n      <td>5050</td>\n      <td>8.097700</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>8.108300</td>\n    </tr>\n    <tr>\n      <td>5150</td>\n      <td>8.104500</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>8.098300</td>\n    </tr>\n    <tr>\n      <td>5250</td>\n      <td>8.109500</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>8.091200</td>\n    </tr>\n    <tr>\n      <td>5350</td>\n      <td>8.097400</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>8.105400</td>\n    </tr>\n    <tr>\n      <td>5450</td>\n      <td>8.111200</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>8.103700</td>\n    </tr>\n    <tr>\n      <td>5550</td>\n      <td>8.087400</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>8.095900</td>\n    </tr>\n    <tr>\n      <td>5650</td>\n      <td>8.099100</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>8.092500</td>\n    </tr>\n    <tr>\n      <td>5750</td>\n      <td>8.103400</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>8.108100</td>\n    </tr>\n    <tr>\n      <td>5850</td>\n      <td>8.101600</td>\n    </tr>\n    <tr>\n      <td>5900</td>\n      <td>8.104900</td>\n    </tr>\n    <tr>\n      <td>5950</td>\n      <td>8.099900</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>8.094200</td>\n    </tr>\n    <tr>\n      <td>6050</td>\n      <td>8.092200</td>\n    </tr>\n    <tr>\n      <td>6100</td>\n      <td>8.106500</td>\n    </tr>\n    <tr>\n      <td>6150</td>\n      <td>8.091500</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>8.101100</td>\n    </tr>\n    <tr>\n      <td>6250</td>\n      <td>8.088400</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>8.098500</td>\n    </tr>\n    <tr>\n      <td>6350</td>\n      <td>8.095800</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>8.094400</td>\n    </tr>\n    <tr>\n      <td>6450</td>\n      <td>8.100100</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>8.099700</td>\n    </tr>\n    <tr>\n      <td>6550</td>\n      <td>8.099600</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>8.099500</td>\n    </tr>\n    <tr>\n      <td>6650</td>\n      <td>8.095900</td>\n    </tr>\n    <tr>\n      <td>6700</td>\n      <td>8.094400</td>\n    </tr>\n    <tr>\n      <td>6750</td>\n      <td>8.107300</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>8.111600</td>\n    </tr>\n    <tr>\n      <td>6850</td>\n      <td>8.096600</td>\n    </tr>\n    <tr>\n      <td>6900</td>\n      <td>8.105600</td>\n    </tr>\n    <tr>\n      <td>6950</td>\n      <td>8.106200</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>8.096600</td>\n    </tr>\n    <tr>\n      <td>7050</td>\n      <td>8.099800</td>\n    </tr>\n    <tr>\n      <td>7100</td>\n      <td>8.102900</td>\n    </tr>\n    <tr>\n      <td>7150</td>\n      <td>8.099000</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>8.100900</td>\n    </tr>\n    <tr>\n      <td>7250</td>\n      <td>8.100400</td>\n    </tr>\n    <tr>\n      <td>7300</td>\n      <td>8.095700</td>\n    </tr>\n    <tr>\n      <td>7350</td>\n      <td>8.101500</td>\n    </tr>\n    <tr>\n      <td>7400</td>\n      <td>8.093400</td>\n    </tr>\n    <tr>\n      <td>7450</td>\n      <td>8.109200</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>8.107900</td>\n    </tr>\n    <tr>\n      <td>7550</td>\n      <td>8.112400</td>\n    </tr>\n    <tr>\n      <td>7600</td>\n      <td>8.111100</td>\n    </tr>\n    <tr>\n      <td>7650</td>\n      <td>8.105700</td>\n    </tr>\n    <tr>\n      <td>7700</td>\n      <td>8.099300</td>\n    </tr>\n    <tr>\n      <td>7750</td>\n      <td>8.087000</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>8.097300</td>\n    </tr>\n    <tr>\n      <td>7850</td>\n      <td>8.100600</td>\n    </tr>\n    <tr>\n      <td>7900</td>\n      <td>8.101100</td>\n    </tr>\n    <tr>\n      <td>7950</td>\n      <td>8.091500</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>8.100600</td>\n    </tr>\n    <tr>\n      <td>8050</td>\n      <td>8.092500</td>\n    </tr>\n    <tr>\n      <td>8100</td>\n      <td>8.091300</td>\n    </tr>\n    <tr>\n      <td>8150</td>\n      <td>8.098800</td>\n    </tr>\n    <tr>\n      <td>8200</td>\n      <td>8.107100</td>\n    </tr>\n    <tr>\n      <td>8250</td>\n      <td>8.097300</td>\n    </tr>\n    <tr>\n      <td>8300</td>\n      <td>8.105500</td>\n    </tr>\n    <tr>\n      <td>8350</td>\n      <td>8.100100</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>8.091400</td>\n    </tr>\n    <tr>\n      <td>8450</td>\n      <td>8.100100</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>8.094300</td>\n    </tr>\n    <tr>\n      <td>8550</td>\n      <td>8.098400</td>\n    </tr>\n    <tr>\n      <td>8600</td>\n      <td>8.088600</td>\n    </tr>\n    <tr>\n      <td>8650</td>\n      <td>8.100200</td>\n    </tr>\n    <tr>\n      <td>8700</td>\n      <td>8.091900</td>\n    </tr>\n    <tr>\n      <td>8750</td>\n      <td>8.098000</td>\n    </tr>\n    <tr>\n      <td>8800</td>\n      <td>8.101100</td>\n    </tr>\n    <tr>\n      <td>8850</td>\n      <td>8.100700</td>\n    </tr>\n    <tr>\n      <td>8900</td>\n      <td>8.101800</td>\n    </tr>\n    <tr>\n      <td>8950</td>\n      <td>8.099500</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>8.085800</td>\n    </tr>\n    <tr>\n      <td>9050</td>\n      <td>8.099900</td>\n    </tr>\n    <tr>\n      <td>9100</td>\n      <td>8.090500</td>\n    </tr>\n    <tr>\n      <td>9150</td>\n      <td>8.082600</td>\n    </tr>\n    <tr>\n      <td>9200</td>\n      <td>8.100000</td>\n    </tr>\n    <tr>\n      <td>9250</td>\n      <td>8.086300</td>\n    </tr>\n    <tr>\n      <td>9300</td>\n      <td>8.093300</td>\n    </tr>\n    <tr>\n      <td>9350</td>\n      <td>8.077800</td>\n    </tr>\n    <tr>\n      <td>9400</td>\n      <td>8.075800</td>\n    </tr>\n    <tr>\n      <td>9450</td>\n      <td>8.082600</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>8.086100</td>\n    </tr>\n    <tr>\n      <td>9550</td>\n      <td>8.090800</td>\n    </tr>\n    <tr>\n      <td>9600</td>\n      <td>8.094300</td>\n    </tr>\n    <tr>\n      <td>9650</td>\n      <td>8.098100</td>\n    </tr>\n    <tr>\n      <td>9700</td>\n      <td>8.098200</td>\n    </tr>\n    <tr>\n      <td>9750</td>\n      <td>8.080000</td>\n    </tr>\n    <tr>\n      <td>9800</td>\n      <td>8.089700</td>\n    </tr>\n    <tr>\n      <td>9850</td>\n      <td>8.084500</td>\n    </tr>\n    <tr>\n      <td>9900</td>\n      <td>8.083300</td>\n    </tr>\n    <tr>\n      <td>9950</td>\n      <td>8.087900</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>8.095300</td>\n    </tr>\n    <tr>\n      <td>10050</td>\n      <td>8.085200</td>\n    </tr>\n    <tr>\n      <td>10100</td>\n      <td>8.090200</td>\n    </tr>\n    <tr>\n      <td>10150</td>\n      <td>8.077800</td>\n    </tr>\n    <tr>\n      <td>10200</td>\n      <td>8.086300</td>\n    </tr>\n    <tr>\n      <td>10250</td>\n      <td>8.086300</td>\n    </tr>\n    <tr>\n      <td>10300</td>\n      <td>8.077800</td>\n    </tr>\n    <tr>\n      <td>10350</td>\n      <td>8.082000</td>\n    </tr>\n    <tr>\n      <td>10400</td>\n      <td>8.091200</td>\n    </tr>\n    <tr>\n      <td>10450</td>\n      <td>8.087600</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>8.092100</td>\n    </tr>\n    <tr>\n      <td>10550</td>\n      <td>8.079900</td>\n    </tr>\n    <tr>\n      <td>10600</td>\n      <td>8.098700</td>\n    </tr>\n    <tr>\n      <td>10650</td>\n      <td>8.081300</td>\n    </tr>\n    <tr>\n      <td>10700</td>\n      <td>8.090900</td>\n    </tr>\n    <tr>\n      <td>10750</td>\n      <td>8.094100</td>\n    </tr>\n    <tr>\n      <td>10800</td>\n      <td>8.096000</td>\n    </tr>\n    <tr>\n      <td>10850</td>\n      <td>8.075700</td>\n    </tr>\n    <tr>\n      <td>10900</td>\n      <td>8.086100</td>\n    </tr>\n    <tr>\n      <td>10950</td>\n      <td>8.088800</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>8.076700</td>\n    </tr>\n    <tr>\n      <td>11050</td>\n      <td>8.080800</td>\n    </tr>\n    <tr>\n      <td>11100</td>\n      <td>8.088800</td>\n    </tr>\n    <tr>\n      <td>11150</td>\n      <td>8.083500</td>\n    </tr>\n    <tr>\n      <td>11200</td>\n      <td>8.079500</td>\n    </tr>\n    <tr>\n      <td>11250</td>\n      <td>8.096500</td>\n    </tr>\n    <tr>\n      <td>11300</td>\n      <td>8.076900</td>\n    </tr>\n    <tr>\n      <td>11350</td>\n      <td>8.097600</td>\n    </tr>\n    <tr>\n      <td>11400</td>\n      <td>8.092900</td>\n    </tr>\n    <tr>\n      <td>11450</td>\n      <td>8.091700</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>8.089700</td>\n    </tr>\n    <tr>\n      <td>11550</td>\n      <td>8.069300</td>\n    </tr>\n    <tr>\n      <td>11600</td>\n      <td>8.086600</td>\n    </tr>\n    <tr>\n      <td>11650</td>\n      <td>8.095900</td>\n    </tr>\n    <tr>\n      <td>11700</td>\n      <td>8.081700</td>\n    </tr>\n    <tr>\n      <td>11750</td>\n      <td>8.088700</td>\n    </tr>\n    <tr>\n      <td>11800</td>\n      <td>8.093200</td>\n    </tr>\n    <tr>\n      <td>11850</td>\n      <td>8.086600</td>\n    </tr>\n    <tr>\n      <td>11900</td>\n      <td>8.098300</td>\n    </tr>\n    <tr>\n      <td>11950</td>\n      <td>8.069000</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>8.078700</td>\n    </tr>\n    <tr>\n      <td>12050</td>\n      <td>8.085600</td>\n    </tr>\n    <tr>\n      <td>12100</td>\n      <td>8.090100</td>\n    </tr>\n    <tr>\n      <td>12150</td>\n      <td>8.097200</td>\n    </tr>\n    <tr>\n      <td>12200</td>\n      <td>8.084300</td>\n    </tr>\n    <tr>\n      <td>12250</td>\n      <td>8.087300</td>\n    </tr>\n    <tr>\n      <td>12300</td>\n      <td>8.080300</td>\n    </tr>\n    <tr>\n      <td>12350</td>\n      <td>8.081300</td>\n    </tr>\n    <tr>\n      <td>12400</td>\n      <td>8.096700</td>\n    </tr>\n    <tr>\n      <td>12450</td>\n      <td>8.094900</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>8.090700</td>\n    </tr>\n    <tr>\n      <td>12550</td>\n      <td>8.084500</td>\n    </tr>\n    <tr>\n      <td>12600</td>\n      <td>8.086600</td>\n    </tr>\n    <tr>\n      <td>12650</td>\n      <td>8.103600</td>\n    </tr>\n    <tr>\n      <td>12700</td>\n      <td>8.091000</td>\n    </tr>\n    <tr>\n      <td>12750</td>\n      <td>8.080400</td>\n    </tr>\n    <tr>\n      <td>12800</td>\n      <td>8.093700</td>\n    </tr>\n    <tr>\n      <td>12850</td>\n      <td>8.086700</td>\n    </tr>\n    <tr>\n      <td>12900</td>\n      <td>8.092200</td>\n    </tr>\n    <tr>\n      <td>12950</td>\n      <td>8.093100</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>8.089500</td>\n    </tr>\n    <tr>\n      <td>13050</td>\n      <td>8.086900</td>\n    </tr>\n    <tr>\n      <td>13100</td>\n      <td>8.076600</td>\n    </tr>\n    <tr>\n      <td>13150</td>\n      <td>8.085600</td>\n    </tr>\n    <tr>\n      <td>13200</td>\n      <td>8.089100</td>\n    </tr>\n    <tr>\n      <td>13250</td>\n      <td>8.078900</td>\n    </tr>\n    <tr>\n      <td>13300</td>\n      <td>8.086500</td>\n    </tr>\n    <tr>\n      <td>13350</td>\n      <td>8.088100</td>\n    </tr>\n    <tr>\n      <td>13400</td>\n      <td>8.091700</td>\n    </tr>\n    <tr>\n      <td>13450</td>\n      <td>8.095800</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>8.089300</td>\n    </tr>\n    <tr>\n      <td>13550</td>\n      <td>8.082800</td>\n    </tr>\n    <tr>\n      <td>13600</td>\n      <td>8.097600</td>\n    </tr>\n    <tr>\n      <td>13650</td>\n      <td>8.081200</td>\n    </tr>\n    <tr>\n      <td>13700</td>\n      <td>8.087200</td>\n    </tr>\n    <tr>\n      <td>13750</td>\n      <td>8.094700</td>\n    </tr>\n    <tr>\n      <td>13800</td>\n      <td>8.084200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1153' max='1153' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1153/1153 11:06]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Final evaluation results: {'eval_runtime': 667.1338, 'eval_samples_per_second': 13.822, 'eval_steps_per_second': 1.728, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import os\n\nmodel_dir = \"./blip-lora-vqa-final\"\nprint(\"Directory exists:\", os.path.exists(model_dir))\nprint(\"Contents:\", os.listdir(model_dir) if os.path.exists(model_dir) else \"N/A\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T00:09:29.192463Z","iopub.execute_input":"2025-05-16T00:09:29.192743Z","iopub.status.idle":"2025-05-16T00:09:29.198195Z","shell.execute_reply.started":"2025-05-16T00:09:29.192718Z","shell.execute_reply":"2025-05-16T00:09:29.197434Z"}},"outputs":[{"name":"stdout","text":"Directory exists: True\nContents: ['adapter_model.safetensors', 'training_args.bin', 'README.md', 'adapter_config.json']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import torch\nfrom transformers import BlipForQuestionAnswering, BlipProcessor\nfrom PIL import Image\n\n# Load model and processor\nmodel_1 = BlipForQuestionAnswering.from_pretrained(\"./blip-lora-vqa-final\")\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_1 = model_1.to(device)\nmodel_1.eval()\n\n# Preview predictions for the first 10 rows\nfor idx, row in test_df.head(10).iterrows():\n    image = Image.open(row['image_path']).convert('RGB')\n    question = row['question']\n    true_answer = row['answer']\n\n    # Preprocess\n    inputs = processor(image, question, return_tensors=\"pt\").to(device)\n\n    # Generate prediction\n    with torch.no_grad():\n        out = model_1.generate(**inputs)\n    predicted_answer = processor.decode(out[0], skip_special_tokens=True)\n\n    print(f\"Row {idx}:\")\n    print(f\"  Question: {question}\")\n    print(f\"  True Answer: {true_answer}\")\n    print(f\"  Predicted Answer: {predicted_answer}\")\n    print(\"-\" * 50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T00:09:29.198905Z","iopub.execute_input":"2025-05-16T00:09:29.199127Z","iopub.status.idle":"2025-05-16T00:09:35.279120Z","shell.execute_reply.started":"2025-05-16T00:09:29.199111Z","shell.execute_reply":"2025-05-16T00:09:35.278541Z"}},"outputs":[{"name":"stdout","text":"Row 9743:\n  Question: What color is it?\n  True Answer: Blue\n  Predicted Answer: blue\n--------------------------------------------------\nRow 31595:\n  Question: What is the frame made of?\n  True Answer: Wood\n  Predicted Answer: wood\n--------------------------------------------------\nRow 28281:\n  Question: What is in the image?\n  True Answer: Handle\n  Predicted Answer: handle\n--------------------------------------------------\nRow 42139:\n  Question: What color is it?\n  True Answer: Gray\n  Predicted Answer: grey\n--------------------------------------------------\nRow 33152:\n  Question: How many screws are there?\n  True Answer: Two\n  Predicted Answer: two\n--------------------------------------------------\nRow 28154:\n  Question: What is the height?\n  True Answer: 96cm\n  Predicted Answer: 80cm\n--------------------------------------------------\nRow 39757:\n  Question: What color is the case?\n  True Answer: Pink\n  Predicted Answer: pink\n--------------------------------------------------\nRow 19645:\n  Question: What color is the fixture?\n  True Answer: Black\n  Predicted Answer: black\n--------------------------------------------------\nRow 35076:\n  Question: What is in the image?\n  True Answer: Ingredients\n  Predicted Answer: ingredients\n--------------------------------------------------\nRow 39489:\n  Question: What is in the image?\n  True Answer: ring\n  Predicted Answer: case\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import time\nimport torch\nfrom transformers import BlipForQuestionAnswering, BlipProcessor\nfrom PIL import Image\n\n# Start timing\nstart_time = time.time()\n\n# 1. Load your fine-tuned model and processor\nmodel_1 = BlipForQuestionAnswering.from_pretrained(\"./blip-lora-vqa-final\")\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n\n# 2. Move model to device (CPU or CUDA)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_1 = model_1.to(device)\nmodel_1.eval()\n\n# 3. Loop over your test DataFrame and generate answers\npred_answers = []\n\nfor idx, row in test_df.iterrows():\n    image = Image.open(row['image_path']).convert('RGB')\n    question = row['question']\n\n    # Preprocess inputs\n    inputs = processor(image, question, return_tensors=\"pt\").to(device)\n\n    # Generate answer\n    with torch.no_grad():\n        out = model_1.generate(**inputs)\n    answer = processor.decode(out[0], skip_special_tokens=True)\n    pred_answers.append(answer)\n\n# 4. Add predictions to your DataFrame as a new column\ntest_df['predicted_answer'] = pred_answers\n\n# End timing\nend_time = time.time()\nelapsed_time = end_time - start_time\n\n# 5. Display or save results\nprint(test_df[['image_path', 'question', 'answer', 'predicted_answer']].head())\nprint(f\"\\n⏱️ Total time taken: {elapsed_time:.2f} seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T00:09:35.280134Z","iopub.execute_input":"2025-05-16T00:09:35.280393Z","iopub.status.idle":"2025-05-16T00:27:40.779993Z","shell.execute_reply.started":"2025-05-16T00:09:35.280372Z","shell.execute_reply":"2025-05-16T00:27:40.779169Z"}},"outputs":[{"name":"stdout","text":"                                              image_path  \\\n9743   /kaggle/input/abo-dataset/images/small/28/2881...   \n31595  /kaggle/input/abo-dataset/images/small/30/3020...   \n28281  /kaggle/input/abo-dataset/images/small/52/52e2...   \n42139  /kaggle/input/abo-dataset/images/small/56/5678...   \n33152  /kaggle/input/abo-dataset/images/small/0f/0fd6...   \n\n                         question  answer predicted_answer  \n9743            What color is it?    Blue             blue  \n31595  What is the frame made of?    Wood             wood  \n28281       What is in the image?  Handle           handle  \n42139           What color is it?    Gray             grey  \n33152  How many screws are there?     Two              two  \n\n⏱️ Total time taken: 1085.49 seconds\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Assuming 'test_df' already has columns: 'answer' (ground truth) and 'predicted_answer'\n# We'll add 'is_true' column: 1 if prediction matches ground truth, else 0\n\n# Normalize answers for comparison (optional but recommended)\ndef normalize(text):\n    return str(text).strip().lower()\n\ntest_df['is_true'] = (test_df['predicted_answer'].apply(normalize) == test_df['answer'].apply(normalize)).astype(int)\n\n# Count number of true and false predictions\nnum_true = test_df['is_true'].sum()\nnum_false = len(test_df) - num_true\n\nprint(f\"Number of correct predictions (is_true=1): {num_true}\")\nprint(f\"Number of incorrect predictions (is_true=0): {num_false}\")\n\n# Save to CSV\ntest_df.to_csv('LORS_PRED_8.csv', index=False)\nprint(\"Results saved to LORS_PRED_8.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T00:27:40.781007Z","iopub.execute_input":"2025-05-16T00:27:40.781464Z","iopub.status.idle":"2025-05-16T00:27:40.829955Z","shell.execute_reply.started":"2025-05-16T00:27:40.781430Z","shell.execute_reply":"2025-05-16T00:27:40.829257Z"}},"outputs":[{"name":"stdout","text":"Number of correct predictions (is_true=1): 6088\nNumber of incorrect predictions (is_true=0): 3133\nResults saved to LORS_PRED_8.csv\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"pip install bitsandbytes transformers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T00:27:40.830738Z","iopub.execute_input":"2025-05-16T00:27:40.831324Z","iopub.status.idle":"2025-05-16T00:27:46.681614Z","shell.execute_reply.started":"2025-05-16T00:27:40.831300Z","shell.execute_reply":"2025-05-16T00:27:46.680670Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.5\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import os\nfrom transformers import BlipForQuestionAnswering, BitsAndBytesConfig\n\nmodel_dir = \"/kaggle/working/blip-lora-vqa-final\"\nprint(\"Model directory contents:\", os.listdir(model_dir))  # Debug: See what files are present\n\n# bnb_config = BitsAndBytesConfig(load_in_8bit=True, llm_int8_threshold=6.0)\n\n# model_2 = BlipForQuestionAnswering.from_pretrained(\n#     model_dir,\n#     quantization_config=bnb_config,\n#     device_map=\"auto\",\n#     local_files_only=True\n# )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T00:27:46.682950Z","iopub.execute_input":"2025-05-16T00:27:46.683619Z","iopub.status.idle":"2025-05-16T00:27:46.689087Z","shell.execute_reply.started":"2025-05-16T00:27:46.683588Z","shell.execute_reply":"2025-05-16T00:27:46.688366Z"}},"outputs":[{"name":"stdout","text":"Model directory contents: ['adapter_model.safetensors', 'training_args.bin', 'README.md', 'adapter_config.json']\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"pip install -U transformers accelerate bitsandbytes\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T00:33:43.283093Z","iopub.execute_input":"2025-05-16T00:33:43.283651Z","iopub.status.idle":"2025-05-16T00:33:47.432212Z","shell.execute_reply.started":"2025-05-16T00:33:43.283625Z","shell.execute_reply":"2025-05-16T00:33:47.431454Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\nCollecting accelerate\n  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.1/362.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.5.2\n    Uninstalling accelerate-1.5.2:\n      Successfully uninstalled accelerate-1.5.2\nSuccessfully installed accelerate-1.7.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"Version 1: Mixed Precision + Manual .to(device)","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport torch\nfrom transformers import BlipForQuestionAnswering, BlipProcessor\nfrom PIL import Image\n\n# Start timer\nstart_time = time.time()\n\n# Load processor and model\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\nmodel_dir = os.path.abspath(\"./blip-lora-vqa-final\")\nprint(\"Loading model from:\", model_dir)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel_2 = BlipForQuestionAnswering.from_pretrained(\n    model_dir,\n    local_files_only=True\n).to(device)\nmodel_2.eval()\n\n# Inference loop\npred_answers = []\nfor idx, row in test_df.iterrows():\n    image = Image.open(row['image_path']).convert('RGB')\n    question = row['question']\n    inputs = processor(image, question, return_tensors=\"pt\")\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n\n    with torch.no_grad(), torch.autocast(device_type=device.type, dtype=torch.bfloat16):\n        out = model_2.generate(**inputs)\n    \n    answer = processor.decode(out[0], skip_special_tokens=True)\n    pred_answers.append(answer)\n\n# Save and display results\ntest_df['predicted_answer'] = pred_answers\nend_time = time.time()\n\nprint(test_df[['image_path', 'question', 'answer', 'predicted_answer']].head())\nprint(f\"\\n⏱️ Total time taken (Mixed Precision): {end_time - start_time:.2f} seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T01:26:46.154877Z","iopub.execute_input":"2025-05-16T01:26:46.155575Z","iopub.status.idle":"2025-05-16T01:54:15.874407Z","shell.execute_reply.started":"2025-05-16T01:26:46.155551Z","shell.execute_reply":"2025-05-16T01:54:15.873596Z"}},"outputs":[{"name":"stdout","text":"Loading model from: /kaggle/working/blip-lora-vqa-final\n                                              image_path  \\\n9743   /kaggle/input/abo-dataset/images/small/28/2881...   \n31595  /kaggle/input/abo-dataset/images/small/30/3020...   \n28281  /kaggle/input/abo-dataset/images/small/52/52e2...   \n42139  /kaggle/input/abo-dataset/images/small/56/5678...   \n33152  /kaggle/input/abo-dataset/images/small/0f/0fd6...   \n\n                         question  answer predicted_answer  \n9743            What color is it?    Blue             blue  \n31595  What is the frame made of?    Wood             wood  \n28281       What is in the image?  Handle           handle  \n42139           What color is it?    Gray             grey  \n33152  How many screws are there?     Two              two  \n\n⏱️ Total time taken (Mixed Precision): 1649.71 seconds\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"Version 2: Batched Inference + Mixed Precision","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport torch\nfrom transformers import BlipForQuestionAnswering, BlipProcessor\nfrom PIL import Image\n\n# Start timer\nstart_time = time.time()\n\n# Load processor and model\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\nmodel_dir = os.path.abspath(\"./blip-lora-vqa-final\")\nprint(\"Loading model from:\", model_dir)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel_2 = BlipForQuestionAnswering.from_pretrained(\n    model_dir,\n    local_files_only=True\n).to(device)\nmodel_2.eval()\n\n# Batch inference\nbatch_size = 4\npred_answers = []\n\nfor i in range(0, len(test_df), batch_size):\n    batch = test_df.iloc[i:i+batch_size]\n    images = [Image.open(p).convert(\"RGB\") for p in batch['image_path']]\n    questions = list(batch['question'])\n\n    inputs = processor(images, questions, return_tensors=\"pt\", padding=True)\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n\n    with torch.no_grad(), torch.autocast(device_type=device.type, dtype=torch.bfloat16):\n        out = model_2.generate(**inputs)\n\n    answers = processor.batch_decode(out, skip_special_tokens=True)\n    pred_answers.extend(answers)\n\n# Save and display results\ntest_df['predicted_answer'] = pred_answers\nend_time = time.time()\n\nprint(test_df[['image_path', 'question', 'answer', 'predicted_answer']].head())\nprint(f\"\\n⏱️ Total time taken (Batched + Mixed Precision): {end_time - start_time:.2f} seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T01:06:25.614808Z","iopub.execute_input":"2025-05-16T01:06:25.615139Z","iopub.status.idle":"2025-05-16T01:24:01.742548Z","shell.execute_reply.started":"2025-05-16T01:06:25.615117Z","shell.execute_reply":"2025-05-16T01:24:01.741846Z"}},"outputs":[{"name":"stdout","text":"Loading model from: /kaggle/working/blip-lora-vqa-final\n                                              image_path  \\\n9743   /kaggle/input/abo-dataset/images/small/28/2881...   \n31595  /kaggle/input/abo-dataset/images/small/30/3020...   \n28281  /kaggle/input/abo-dataset/images/small/52/52e2...   \n42139  /kaggle/input/abo-dataset/images/small/56/5678...   \n33152  /kaggle/input/abo-dataset/images/small/0f/0fd6...   \n\n                         question  answer predicted_answer  \n9743            What color is it?    Blue             blue  \n31595  What is the frame made of?    Wood             wood  \n28281       What is in the image?  Handle           handle  \n42139           What color is it?    Gray             grey  \n33152  How many screws are there?     Two              two  \n\n⏱️ Total time taken (Batched + Mixed Precision): 1056.12 seconds\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# import os\n# import time\n# import torch\n# from transformers import BlipForQuestionAnswering, BlipProcessor, BitsAndBytesConfig\n# from PIL import Image\n\n# # Start timing\n# start_time = time.time()\n\n# # Define model path\n# model_dir = os.path.abspath(\"./blip-lora-vqa-final\")  # change if needed\n# print(\"Loading model from:\", model_dir)\n\n# # Load processor\n# processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n\n# # Quantization config\n# bnb_config = BitsAndBytesConfig(\n#     load_in_8bit=True,              # 8-bit quantization\n#     llm_int8_threshold=6.0,\n#     llm_int8_skip_modules=None,\n# )\n\n# # Load quantized model\n# model_2 = BlipForQuestionAnswering.from_pretrained(\n#     model_dir,\n#     device_map=\"auto\",\n#     quantization_config=bnb_config,\n#     local_files_only=True\n# )\n# model_2.eval()\n\n# # Move model to appropriate device\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # Inference loop\n# pred_answers = []\n# for idx, row in test_df.iterrows():\n#     image = Image.open(row['image_path']).convert('RGB')\n#     question = row['question']\n#     inputs = processor(image, question, return_tensors=\"pt\").to(device)\n#     with torch.no_grad():\n#         out = model_2.generate(**inputs)\n#     answer = processor.decode(out[0], skip_special_tokens=True)\n#     pred_answers.append(answer)\n\n# test_df['predicted_answer'] = pred_answers\n\n# # End timing\n# end_time = time.time()\n# print(test_df[['image_path', 'question', 'answer', 'predicted_answer']].head())\n# print(f\"\\n⏱️ Total time taken: {end_time - start_time:.2f} seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T01:25:54.568161Z","iopub.execute_input":"2025-05-16T01:25:54.568874Z","iopub.status.idle":"2025-05-16T01:25:54.572617Z","shell.execute_reply.started":"2025-05-16T01:25:54.568849Z","shell.execute_reply":"2025-05-16T01:25:54.571942Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def normalize(text):\n    return str(text).strip().lower()\n\ntest_df['is_true'] = (test_df['predicted_answer'].apply(normalize) == test_df['answer'].apply(normalize)).astype(int)\nnum_true = test_df['is_true'].sum()\nnum_false = len(test_df) - num_true\n\nprint(f\"Number of correct predictions (is_true=1): {num_true}\")\nprint(f\"Number of incorrect predictions (is_true=0): {num_false}\")\ntest_df.to_csv('LORS_PRED_8_QUANT.csv', index=False)\nprint(\"Results saved to LORS_PRED_8_QUANT.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T01:25:32.630453Z","iopub.execute_input":"2025-05-16T01:25:32.630732Z","iopub.status.idle":"2025-05-16T01:25:32.677816Z","shell.execute_reply.started":"2025-05-16T01:25:32.630714Z","shell.execute_reply":"2025-05-16T01:25:32.677276Z"}},"outputs":[{"name":"stdout","text":"Number of correct predictions (is_true=1): 6059\nNumber of incorrect predictions (is_true=0): 3162\nResults saved to LORS_PRED_8_QUANT.csv\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"Flash Attention (with xformers backend)","metadata":{}},{"cell_type":"code","source":"pip install xformers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T01:56:52.785009Z","iopub.execute_input":"2025-05-16T01:56:52.785324Z","iopub.status.idle":"2025-05-16T01:59:50.413615Z","shell.execute_reply.started":"2025-05-16T01:56:52.785301Z","shell.execute_reply":"2025-05-16T01:59:50.412509Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting xformers\n  Downloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers) (1.26.4)\nCollecting torch==2.7.0 (from xformers)\n  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->xformers) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->xformers) (4.13.2)\nCollecting sympy>=1.13.3 (from torch==2.7.0->xformers)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->xformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->xformers) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->xformers) (2025.3.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.0->xformers)\n  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.0->xformers)\n  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.0->xformers)\n  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.0->xformers)\n  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.0->xformers)\n  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.0->xformers)\n  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.0->xformers)\n  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.0->xformers)\n  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.0->xformers)\n  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.0->xformers)\n  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.0->xformers)\n  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.0->xformers)\n  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.0->xformers)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.0->xformers)\n  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.3.0 (from torch==2.7.0->xformers)\n  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch==2.7.0->xformers) (75.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->xformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->xformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->xformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->xformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->xformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->xformers) (2.4.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.0->xformers) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.0->xformers) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->xformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->xformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->xformers) (2024.2.0)\nDownloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl (31.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, xformers\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.5.147\n    Uninstalling nvidia-curand-cu12-10.3.5.147:\n      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\ntorchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.0 triton-3.3.0 xformers-0.0.30\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import os\nimport time\nimport torch\nimport pandas as pd\nfrom transformers import BlipForQuestionAnswering, BlipProcessor\nfrom PIL import Image\n\n# Your test dataframe (replace with actual loading logic)\n# Example:\n# test_df = pd.read_csv(\"test_data.csv\")  # Columns: image_path, question, answer\n\n# Setup\ntorch.backends.cuda.matmul.allow_tf32 = True\nos.environ[\"XFORMERS_FORCE_DISABLE\"] = \"0\"\n\nstart_time = time.time()\n\n# Load processor and model\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Load fine-tuned model (no device_map, load directly to single GPU)\nmodel_dir = os.path.abspath(\"./blip-lora-vqa-final\")\nprint(\"Loading model from:\", model_dir)\nmodel_2 = BlipForQuestionAnswering.from_pretrained(\n    model_dir,\n    local_files_only=True,\n    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n)\nmodel_2.to(device)\nmodel_2.eval()\n\n# Inference loop\npred_answers = []\n\nfor idx, row in test_df.iterrows():\n    image = Image.open(row['image_path']).convert('RGB')\n    question = row['question']\n\n    # Prepare inputs\n    inputs = processor(image, question, return_tensors=\"pt\")\n    \n    # Move pixel_values to float16, others remain as int\n    inputs['pixel_values'] = inputs['pixel_values'].to(device=device, dtype=torch.float16)\n    inputs['input_ids'] = inputs['input_ids'].to(device)\n    inputs['attention_mask'] = inputs['attention_mask'].to(device)\n\n    with torch.no_grad():\n        out = model_2.generate(**inputs)\n\n    answer = processor.decode(out[0], skip_special_tokens=True)\n    pred_answers.append(answer)\n\n# Save predictions to DataFrame\ntest_df['predicted_answer'] = pred_answers\n\nend_time = time.time()\nprint(test_df[['image_path', 'question', 'answer', 'predicted_answer']].head())\nprint(f\"\\n⏱️ Flash-Attn Optimized Time: {end_time - start_time:.2f} seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T02:28:20.897214Z","iopub.execute_input":"2025-05-16T02:28:20.897948Z","iopub.status.idle":"2025-05-16T02:45:39.418430Z","shell.execute_reply.started":"2025-05-16T02:28:20.897923Z","shell.execute_reply":"2025-05-16T02:45:39.417746Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda:0\nLoading model from: /kaggle/working/blip-lora-vqa-final\n                                              image_path  \\\n9743   /kaggle/input/abo-dataset/images/small/28/2881...   \n31595  /kaggle/input/abo-dataset/images/small/30/3020...   \n28281  /kaggle/input/abo-dataset/images/small/52/52e2...   \n42139  /kaggle/input/abo-dataset/images/small/56/5678...   \n33152  /kaggle/input/abo-dataset/images/small/0f/0fd6...   \n\n                         question  answer predicted_answer  \n9743            What color is it?    Blue             blue  \n31595  What is the frame made of?    Wood             wood  \n28281       What is in the image?  Handle           handle  \n42139           What color is it?    Gray             grey  \n33152  How many screws are there?     Two              two  \n\n⏱️ Flash-Attn Optimized Time: 1038.51 seconds\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"2. TorchScript (Static Graph Compilation)","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport torch\nfrom transformers import BlipForQuestionAnswering, BlipProcessor\nfrom PIL import Image\n\nstart_time = time.time()\n\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\nmodel_dir = os.path.abspath(\"./blip-lora-vqa-final\")\nprint(\"Loading model from:\", model_dir)\n\nmodel_2 = BlipForQuestionAnswering.from_pretrained(\n    model_dir,\n    local_files_only=True\n).to(\"cuda\").eval()\n\npred_answers = []\nfor idx, row in test_df.iterrows():\n    image = Image.open(row['image_path']).convert('RGB')\n    question = row['question']\n    inputs = processor(image, question, return_tensors=\"pt\").to(\"cuda\")\n    with torch.no_grad():\n        out = model_2.generate(**inputs)\n    answer = processor.decode(out[0], skip_special_tokens=True)\n    pred_answers.append(answer)\n\ntest_df['predicted_answer'] = pred_answers\nend_time = time.time()\n\nprint(test_df[['image_path', 'question', 'answer', 'predicted_answer']].head())\nprint(f\"\\n⏱️ Inference Time: {end_time - start_time:.2f} seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:04:02.043276Z","iopub.execute_input":"2025-05-16T03:04:02.043491Z","iopub.status.idle":"2025-05-16T03:22:26.977174Z","shell.execute_reply.started":"2025-05-16T03:04:02.043474Z","shell.execute_reply":"2025-05-16T03:22:26.976435Z"}},"outputs":[{"name":"stdout","text":"Loading model from: /kaggle/working/blip-lora-vqa-final\n                                              image_path  \\\n9743   /kaggle/input/abo-dataset/images/small/28/2881...   \n31595  /kaggle/input/abo-dataset/images/small/30/3020...   \n28281  /kaggle/input/abo-dataset/images/small/52/52e2...   \n42139  /kaggle/input/abo-dataset/images/small/56/5678...   \n33152  /kaggle/input/abo-dataset/images/small/0f/0fd6...   \n\n                         question  answer predicted_answer  \n9743            What color is it?    Blue             blue  \n31595  What is the frame made of?    Wood             wood  \n28281       What is in the image?  Handle           handle  \n42139           What color is it?    Gray             grey  \n33152  How many screws are there?     Two              two  \n\n⏱️ Inference Time: 1104.92 seconds\n","output_type":"stream"}],"execution_count":36}]}